{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "796e2afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "599e9764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.13.9 environment at: C:\\Users\\DELL\\Desktop\\GenAI-Document-Portal\\.venv\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m94 packages\u001b[0m \u001b[2min 2.50s\u001b[0m\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m cryptography \u001b[2m(3.3MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m grpcio \u001b[2m(4.6MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m google-cloud-aiplatform \u001b[2m(7.8MiB)\u001b[0m\n",
      " \u001b[36m\u001b[1mDownloaded\u001b[0m\u001b[39m cryptography\n",
      " \u001b[36m\u001b[1mDownloaded\u001b[0m\u001b[39m grpcio\n",
      " \u001b[36m\u001b[1mDownloaded\u001b[0m\u001b[39m google-cloud-aiplatform\n",
      "\u001b[2mPrepared \u001b[1m25 packages\u001b[0m \u001b[2min 7.29s\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m25 packages\u001b[0m \u001b[2min 1.31s\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcffi\u001b[0m\u001b[2m==2.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcryptography\u001b[0m\u001b[2m==46.0.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdocstring-parser\u001b[0m\u001b[2m==0.17.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-api-core\u001b[0m\u001b[2m==2.30.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-auth\u001b[0m\u001b[2m==2.48.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-cloud-aiplatform\u001b[0m\u001b[2m==1.138.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-cloud-bigquery\u001b[0m\u001b[2m==3.40.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-cloud-core\u001b[0m\u001b[2m==2.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-cloud-resource-manager\u001b[0m\u001b[2m==1.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-cloud-storage\u001b[0m\u001b[2m==3.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-cloud-translate\u001b[0m\u001b[2m==3.24.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-cloud-vision\u001b[0m\u001b[2m==3.12.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-crc32c\u001b[0m\u001b[2m==1.8.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-genai\u001b[0m\u001b[2m==1.64.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-resumable-media\u001b[0m\u001b[2m==2.8.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogleapis-common-protos\u001b[0m\u001b[2m==1.72.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgrpc-google-iam-v1\u001b[0m\u001b[2m==0.14.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgrpcio\u001b[0m\u001b[2m==1.78.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgrpcio-status\u001b[0m\u001b[2m==1.78.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mproto-plus\u001b[0m\u001b[2m==1.27.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyasn1\u001b[0m\u001b[2m==0.6.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyasn1-modules\u001b[0m\u001b[2m==0.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpycparser\u001b[0m\u001b[2m==3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrsa\u001b[0m\u001b[2m==4.9.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==15.0.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install langchain google-cloud-vision google-cloud-translate google-cloud-aiplatform rapidocr-onnxruntime python-dotenv langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d86b3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.13.9 environment at: C:\\Users\\DELL\\Desktop\\GenAI-Document-Portal\\.venv\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m27 packages\u001b[0m \u001b[2min 901ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m27 packages\u001b[0m \u001b[2min 1ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install -U langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a41e121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f3c569",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32bea3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97f3c5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"C:/Users/DELL/Desktop/GenAI-Document-Portal/data/Agentic_AI.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c43dcf36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7890ccf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:/Users/DELL/Desktop/GenAI-Document-Portal/data/Agentic_AI.txt'}, page_content='Agentic AI refers to artificial intelligence systems that go beyond passive response and act with \\nautonomy, reasoning, and tool use. Unlike traditional models that only generate outputs when \\nprompted, agentic systems can plan tasks, select strategies, and orchestrate actions toward a goal.\\n They operate in a loop of perception, planning, and execution: first interpreting the context, \\n then breaking down the problem into steps, and finally choosing the right tools or APIs to \\n complete each step.\\n\\nFor example, when asked to summarize a research paper, an agentic AI doesn’t just produce text. It \\nmay load the document, parse its structure, extract key sections, and then apply a language model \\nto generate a concise summary. If the input is an image, it might call an OCR service to extract\\ntext before reasoning about the content. This ability to combine multiple capabilities dynamically\\nmakes agentic AI more powerful and flexible than static models.\\n\\nThe defining traits of agentic AI are:\\n\\nAutonomy: It can initiate actions beyond a single prompt.\\n\\nReasoning: It decomposes complex tasks into manageable steps.\\n\\nTool use: It integrates external services (databases, APIs, search engines) to achieve goals.\\n\\nAdaptability: It monitors outcomes and adjusts its approach when conditions change.\\n\\nIn practice, agentic AI is the foundation of modern GenAI applications — \\nfrom chatbots that can book tickets or translate documents, to research assistants that can \\nretrieve data, analyze it, and present insights. It represents a shift from “AI as a \\npassive model” to “AI as an active collaborator,” capable of decision-making, execution, and \\ncontinuous improvement.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abef5891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Agentic AI refers to artificial intelligence systems that go beyond passive response and act with \\nautonomy, reasoning, and tool use. Unlike traditional models that only generate outputs when \\nprompted, agentic systems can plan tasks, select strategies, and orchestrate actions toward a goal.\\n They operate in a loop of perception, planning, and execution: first interpreting the context, \\n then breaking down the problem into steps, and finally choosing the right tools or APIs to \\n complete each step.\\n\\nFor example, when asked to summarize a research paper, an agentic AI doesn’t just produce text. It \\nmay load the document, parse its structure, extract key sections, and then apply a language model \\nto generate a concise summary. If the input is an image, it might call an OCR service to extract\\ntext before reasoning about the content. This ability to combine multiple capabilities dynamically\\nmakes agentic AI more powerful and flexible than static models.\\n\\nThe defining traits of agentic AI are:\\n\\nAutonomy: It can initiate actions beyond a single prompt.\\n\\nReasoning: It decomposes complex tasks into manageable steps.\\n\\nTool use: It integrates external services (databases, APIs, search engines) to achieve goals.\\n\\nAdaptability: It monitors outcomes and adjusts its approach when conditions change.\\n\\nIn practice, agentic AI is the foundation of modern GenAI applications — \\nfrom chatbots that can book tickets or translate documents, to research assistants that can \\nretrieve data, analyze it, and present insights. It represents a shift from “AI as a \\npassive model” to “AI as an active collaborator,” capable of decision-making, execution, and \\ncontinuous improvement.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36eab934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd6de554",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 200, chunk_overlap = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7106046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "110010b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8681167f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'C:/Users/DELL/Desktop/GenAI-Document-Portal/data/Agentic_AI.txt'}, page_content='Agentic AI refers to artificial intelligence systems that go beyond passive response and act with \\nautonomy, reasoning, and tool use. Unlike traditional models that only generate outputs when'),\n",
       " Document(metadata={'source': 'C:/Users/DELL/Desktop/GenAI-Document-Portal/data/Agentic_AI.txt'}, page_content='prompted, agentic systems can plan tasks, select strategies, and orchestrate actions toward a goal.\\n They operate in a loop of perception, planning, and execution: first interpreting the context,'),\n",
       " Document(metadata={'source': 'C:/Users/DELL/Desktop/GenAI-Document-Portal/data/Agentic_AI.txt'}, page_content='then breaking down the problem into steps, and finally choosing the right tools or APIs to \\n complete each step.'),\n",
       " Document(metadata={'source': 'C:/Users/DELL/Desktop/GenAI-Document-Portal/data/Agentic_AI.txt'}, page_content='For example, when asked to summarize a research paper, an agentic AI doesn’t just produce text. It \\nmay load the document, parse its structure, extract key sections, and then apply a language model'),\n",
       " Document(metadata={'source': 'C:/Users/DELL/Desktop/GenAI-Document-Portal/data/Agentic_AI.txt'}, page_content='to generate a concise summary. If the input is an image, it might call an OCR service to extract\\ntext before reasoning about the content. This ability to combine multiple capabilities dynamically'),\n",
       " Document(metadata={'source': 'C:/Users/DELL/Desktop/GenAI-Document-Portal/data/Agentic_AI.txt'}, page_content='makes agentic AI more powerful and flexible than static models.'),\n",
       " Document(metadata={'source': 'C:/Users/DELL/Desktop/GenAI-Document-Portal/data/Agentic_AI.txt'}, page_content='The defining traits of agentic AI are:\\n\\nAutonomy: It can initiate actions beyond a single prompt.\\n\\nReasoning: It decomposes complex tasks into manageable steps.'),\n",
       " Document(metadata={'source': 'C:/Users/DELL/Desktop/GenAI-Document-Portal/data/Agentic_AI.txt'}, page_content='Tool use: It integrates external services (databases, APIs, search engines) to achieve goals.\\n\\nAdaptability: It monitors outcomes and adjusts its approach when conditions change.'),\n",
       " Document(metadata={'source': 'C:/Users/DELL/Desktop/GenAI-Document-Portal/data/Agentic_AI.txt'}, page_content='In practice, agentic AI is the foundation of modern GenAI applications — \\nfrom chatbots that can book tickets or translate documents, to research assistants that can'),\n",
       " Document(metadata={'source': 'C:/Users/DELL/Desktop/GenAI-Document-Portal/data/Agentic_AI.txt'}, page_content='retrieve data, analyze it, and present insights. It represents a shift from “AI as a \\npassive model” to “AI as an active collaborator,” capable of decision-making, execution, and'),\n",
       " Document(metadata={'source': 'C:/Users/DELL/Desktop/GenAI-Document-Portal/data/Agentic_AI.txt'}, page_content='continuous improvement.')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6493cbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.13.9 environment at: C:\\Users\\DELL\\Desktop\\GenAI-Document-Portal\\.venv\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m3 packages\u001b[0m \u001b[2min 734ms\u001b[0m\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m faiss-cpu \u001b[2m(18.0MiB)\u001b[0m\n",
      " \u001b[36m\u001b[1mDownloaded\u001b[0m\u001b[39m faiss-cpu\n",
      "\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 7.21s\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 29ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfaiss-cpu\u001b[0m\u001b[2m==1.13.2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29f35dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.13.9 environment at: C:\\Users\\DELL\\Desktop\\GenAI-Document-Portal\\.venv\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m47 packages\u001b[0m \u001b[2min 1.13s\u001b[0m\u001b[0m\n",
      "\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 126ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 74ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfiletype\u001b[0m\u001b[2m==1.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-google-genai\u001b[0m\u001b[2m==4.2.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install -U langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9696a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e7e828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "efb2cdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(text_chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "27a716e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x230ebeefe00>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffda1052",
   "metadata": {},
   "source": [
    "## Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af2da348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1\n",
      "Agentic AI refers to artificial intelligence systems that go beyond passive response and act with \n",
      "autonomy, reasoning, and tool use. Unlike traditional models that only generate outputs when\n",
      "--------------------------------------------------\n",
      "Document 2\n",
      "The defining traits of agentic AI are:\n",
      "\n",
      "Autonomy: It can initiate actions beyond a single prompt.\n",
      "\n",
      "Reasoning: It decomposes complex tasks into manageable steps.\n",
      "--------------------------------------------------\n",
      "Document 3\n",
      "makes agentic AI more powerful and flexible than static models.\n",
      "--------------------------------------------------\n",
      "Document 4\n",
      "prompted, agentic systems can plan tasks, select strategies, and orchestrate actions toward a goal.\n",
      " They operate in a loop of perception, planning, and execution: first interpreting the context,\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## Perform similarity search\n",
    "query = \"What is the key characteristics of Agentic AI ?\"\n",
    "docs = vectorstore.similarity_search(query, k = 4)\n",
    "\n",
    "## Display the results\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"Document {i + 1}\")\n",
    "    print(doc.page_content)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c358bbb",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dfc7deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f58eac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\" You are an assistant for qusetion - answering tasks.\n",
    "Use the following pieces of retrieval context to answer the question.\n",
    "If you dont know the answer, just say that you don't know.\n",
    "Use ten sentences maximum and keep the answer concise.\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "15ddd21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "134e0811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\" You are an assistant for qusetion - answering tasks.\\nUse the following pieces of retrieval context to answer the question.\\nIf you dont know the answer, just say that you don't know.\\nUse ten sentences maximum and keep the answer concise.\\nQuestion: {question}\\nContext: {context}\\nAnswer:\\n\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "abf4696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b37f3811",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9e3c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI \n",
    "llm_model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eab43feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e764ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d05f9f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever,              # retrieves docs\n",
    "        \"question\": RunnablePassthrough()  # passes user input\n",
    "    }\n",
    "    | prompt                               # formats into a prompt\n",
    "    | llm_model                            # sends to LLM\n",
    "    | output_parser                        # parses output\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f232f74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Agentic AI systems are characterized by autonomy, reasoning, and tool use, allowing them to act beyond passive responses. They can initiate actions beyond a single prompt and decompose complex tasks into manageable steps. These systems plan tasks, select strategies, and orchestrate actions toward a goal, operating in a loop of perception, planning, and execution. This makes agentic AI more powerful and flexible than static models.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is the key characteristics of Agentic AI ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af707965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-document-portal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
