Steps to achieve the project goal

1. Set up uv environment in your project directory
   a. First check if uv setup is there "uv --version"
   b. If set up not there, run "powershell -c "irm https://astral.sh/uv/install.ps1 | iex" in powershell
   c. In environment variable set up the path
   d. Once setup is done, run "uv init ." in your terminal. Your uv environment will be set up.

2. Create a virtual environment with the help of uv
   a. Run in terminal "uv venv .venv"  (dont do this)
   b. Create a requirements.txt file, write the command "python-dotenv"
   c. Run in terminal "uv add -r requirements.txt"
3. Run in terminal "uv add ipykernel"   
4. Run in terminal "uv sync"  (Add synchronization between dependencies in files and folders)
5. Create the required folders for our project
   a. data (Here, we will store the data incoming from user, also will store processed data here)
   b. multi_doc_chat (This is where we will write the actual modular structure code)
      It includes - 1. config 2. exception  3. logger 4. model 5. prompts 6. src 7. utils
6. Create a notebook folder for running experiments.
7. Create a static folder -> style.css (Here, we will have the css files)
8. Create a templates folder -> html files (Here, we will have html files for the frontend part)
9. Create a test folder, here we will do the testing part like unit test, integration test  

----  Lets look at some of the dependencies that we will be installing  -------
1. google-cloud-vision → Lets you use Google’s Vision API for OCR and image analysis. You can extract text from images, detect objects, or classify content without building your own OCR pipeline.
2. google-cloud-translate → Provides access to Google’s Translation API. It allows you to translate text between languages programmatically, useful for multilingual GenAI applications.
3. google-cloud-aiplatform → Connects to Google’s Vertex AI, where you can access Google’s large language models (like PaLM) and manage ML workflows. This is how you run LLMs on Google Cloud instead of OpenAI.
4. langchain + langchain-community → A framework for orchestrating LLM workflows. It helps you chain prompts, tools, and data sources together (e.g., OCR → translation → LLM → response). The community package adds extra integrations maintained outside the core library.
5. rapidocr-onnxruntime → A lightweight, local OCR engine that runs on ONNX Runtime. Useful if you want OCR without calling Google Vision (faster, cheaper, and works offline).
6. python-dotenv → Loads environment variables from a .env file. This keeps your API keys (Google or OpenAI) secure and separate from your code, so you don’t hardcode secrets.

